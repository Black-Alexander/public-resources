{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "_README_ = '''\n",
    "-------------------------------------------------------------------------\n",
    "Generate JSON files for GBE decomposition page.\n",
    "-p option outputs python numpy npz file (compressed format) for python\n",
    "\n",
    "Author: Yosuke Tanigawa (ytanigaw@stanford.edu)\n",
    "Date: 2017/12/01\n",
    "-------------------------------------------------------------------------\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "from scipy.sparse import dok_matrix\n",
    "import argparse\n",
    "import logging\n",
    "from logging.config import dictConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging_config = dict(\n",
    "    version = 1,\n",
    "    formatters = {\n",
    "        'f': {'format':\n",
    "              '%(asctime)s %(name)-12s %(levelname)-8s %(message)s'}\n",
    "        },\n",
    "    handlers = {\n",
    "        'h': {'class': 'logging.StreamHandler',\n",
    "              'formatter': 'f',\n",
    "              'level': logging.DEBUG}\n",
    "        },\n",
    "    root = {\n",
    "        'handlers': ['h'],\n",
    "        #'level': logging.INFO,\n",
    "        'level': logging.DEBUG,\n",
    "        },\n",
    ")\n",
    "dictConfig(logging_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_label_phe(label_phe_f):\n",
    "    label_phe_df = pd.read_csv(label_phe_f, sep='\\t')\n",
    "    label_phe_code = label_phe_df['icd'].as_matrix()   \n",
    "    label_phe      = label_phe_df['Name'].map(lambda x: re.sub('_', ' ', re.sub('_/_', '/', x))).as_matrix()\n",
    "    return label_phe, label_phe_code\n",
    "\n",
    "\n",
    "def parse_label_var(label_var_f):\n",
    "    label_var_df = pd.read_csv(label_var_f, sep='\\t')\n",
    "    return label_var_df['signature'].map(lambda x: re.sub('_', '-', x)).as_matrix()\n",
    "\n",
    "\n",
    "def read_eigen_values(tsvd_f):\n",
    "    eigen_v_dict = dict([])\n",
    "    with open(tsvd_f) as f:\n",
    "        for line in f:\n",
    "            l = line.split('\\t')\n",
    "            if(l[0] == '1'):\n",
    "                eigen_v_dict[int(l[2])] = float(l[3])\n",
    "    return np.array([eigen_v_dict[x] for x in sorted(eigen_v_dict.keys())])\n",
    "\n",
    "\n",
    "def read_eigen_vectors(tsvd_f, n_PCs, n_phes, n_vars):\n",
    "    eigen_phe_dok = dok_matrix((n_phes, n_PCs), dtype = np.float)\n",
    "    eigen_var_dok = dok_matrix((n_vars, n_PCs), dtype = np.float)    \n",
    "    with open(tsvd_f) as f:\n",
    "        for line in f:\n",
    "            l = line.split('\\t')\n",
    "            if(  l[0] == '0' and int(l[1]) < n_phes and int(l[2]) < n_PCs):\n",
    "                eigen_phe_dok[int(l[1]), int(l[2])] = float(l[3])\n",
    "            elif(l[0] == '2' and int(l[2]) < n_vars and int(l[1]) < n_PCs):\n",
    "                eigen_var_dok[int(l[2]), int(l[1])] = float(l[3]) \n",
    "    return np.array(eigen_phe_dok.todense()), np.array(eigen_var_dok.todense())\n",
    "\n",
    "\n",
    "def dok_from_tsv(tsv_f, dtype=np.float):\n",
    "    logger = logging.getLogger('dok_from_tsv')\n",
    "    logger.info('reading {}'.format(tsv_f))\n",
    "    df = pd.read_csv(tsv_f, sep='\\t')\n",
    "    logger.info('constructing a dok matrix of size {} x {}'.format(len(set(df.ix[:, 0])), len(set(df.ix[:, 1]))))\n",
    "    dok_mat = dok_matrix(\n",
    "        (len(set(df.ix[:, 0])), len(set(df.ix[:, 1]))),\n",
    "        dtype = dtype\n",
    "    )\n",
    "    dok_mat.update(\n",
    "        dict(\n",
    "            zip(\n",
    "                zip(\n",
    "                    df.ix[:, 0].tolist(), \n",
    "                    df.ix[:, 1].tolist()\n",
    "                ),\n",
    "                df.ix[:, 2].tolist()\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return dok_mat\n",
    "\n",
    "\n",
    "def compute_factor(eigen_vec, eigen_values):\n",
    "    return np.dot(eigen_vec, np.diag(eigen_values))\n",
    "\n",
    "\n",
    "def compute_contribution(factor):\n",
    "    return (factor ** 2) / (np.sum(factor ** 2, axis = 0).reshape((1, factor.shape[1])))\n",
    "\n",
    "\n",
    "def compute_cos(factor):\n",
    "    return (factor ** 2) / (np.sum(factor ** 2, axis = 1).reshape((factor.shape[0], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_contribution_gene(\n",
    "    var2gene_dict, label_var, contribution_var\n",
    "):\n",
    "    contribution_var_df = pd.DataFrame(contribution_var)    \n",
    "    contribution_var_df['gene'] = [var2gene_dict[x] for x in label_var]\n",
    "    contribution_gene_df = contribution_var_df.groupby('gene').sum()\n",
    "    \n",
    "    return contribution_gene_df.as_matrix(), np.array(contribution_gene_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data_mat_for_stacked_bar(contribution_scores, label, threshold):    \n",
    "    def generate_mask_for_contribution_scores(contribution_scores, threshold):\n",
    "        return np.apply_along_axis(\n",
    "            lambda l: reduce(lambda x, y: x or y, l), 1, \n",
    "            np.vectorize(lambda z: z > threshold)(np.array(contribution_scores))\n",
    "        )    \n",
    "       \n",
    "    mask = generate_mask_for_contribution_scores(contribution_scores, threshold)\n",
    "    stacked_bar_label = np.hstack([np.array(label[mask]), ['others']])\n",
    "    truncated_data = contribution_scores[mask, :]    \n",
    "    #truncated_data[truncated_data < threshold] = 0    \n",
    "    stacked_bar_data  = np.vstack([truncated_data, 1 - truncated_data.sum(axis = 0)])\n",
    "\n",
    "    return stacked_bar_data, stacked_bar_label\n",
    "\n",
    "\n",
    "def stacked_bar_per_pc(stacked_bar_data, stacked_bar_label, pc):\n",
    "    sort_order = (-stacked_bar_data[:-1, pc]).argsort() \n",
    "    data  = stacked_bar_data[sort_order, pc][:50].tolist()\n",
    "    label = stacked_bar_label[sort_order][:50].tolist()\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sparsify_contributoin_scores(contribution_mat, label, pci, threshold=0.0001):\n",
    "#    mask = contribution_mat[:, pci] > (0.1 / contribution_mat.shape[0])\n",
    "    mask = contribution_mat[:, pci] > threshold\n",
    "    xs = np.arange(contribution_mat.shape[0])[mask]\n",
    "    ys = contribution_mat[mask, pci]\n",
    "    ls = label[mask]\n",
    "    return xs, ys, ls, mask\n",
    "\n",
    "\n",
    "def get_label_var_to_label_gene_dict(tsv_file):\n",
    "    df = pd.read_csv(tsv_file, sep='\\t')\n",
    "    return dict(zip(df['label_var'], df['label_gene']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_json_misc(\n",
    "    out_dir, dataset, metadata, n_PCs, total_inertia, eigen_v, \n",
    "    label_phe, label_var, label_phe_code, label_gene,\n",
    "    label_phe_stackedbar, label_gene_stackedbar,\n",
    "    stackedbar_phe, stackedbar_gene):\n",
    "    \n",
    "#    eigen_relative = eigen_v ** 2 / np.sum(eigen_v ** 2)\n",
    "    eigen_relative = eigen_v ** 2 / total_inertia\n",
    "\n",
    "    if not os.path.exists(os.path.join(out_dir, dataset)):\n",
    "        os.makedirs(os.path.join(out_dir, dataset))\n",
    "        \n",
    "    stackedbar_phe_json = [\n",
    "        {\n",
    "            'x':['PC{}'.format(pc + 1) for pc in range(n_PCs)],\n",
    "            'y':stackedbar_phe[i].tolist(),\n",
    "            'name': label_phe_stackedbar[i],\n",
    "            'type': 'bar',\n",
    "            'hoverinfo': 'none'\n",
    "        } for i in range(stackedbar_phe.shape[0])\n",
    "    ]\n",
    "    \n",
    "    stackedbar_gene_json = [\n",
    "        {\n",
    "            'x':['PC{}'.format(pc + 1) for pc in range(n_PCs)],\n",
    "            'y':stackedbar_gene[i].tolist(),\n",
    "            'name': label_gene_stackedbar[i],\n",
    "            'type': 'bar',\n",
    "            'hoverinfo': 'none'\n",
    "        } for i in range(stackedbar_gene.shape[0])\n",
    "    ]                    \n",
    "        \n",
    "    with open(os.path.join(out_dir, dataset, '{}_misc.json'.format(dataset)), 'w') as f:\n",
    "            json.dump({\n",
    "                'metadata' : metadata,\n",
    "                'total_inertia' : total_inertia,\n",
    "                'eigen_v'  : eigen_v.tolist(),\n",
    "                'eigen_r'  : eigen_relative.tolist(),\n",
    "                'label_phe': label_phe,\n",
    "                'label_var': label_var,\n",
    "                'label_phe_code' : label_phe_code,\n",
    "                'label_phe_code_idx' : dict(zip(label_phe_code, range(len(label_phe_code)))),\n",
    "                'label_gene' : label_gene,\n",
    "                'label_pc':  ['PC{}'.format(pci + 1) for pci in range(n_PCs)],\n",
    "                'label_pc_idx':  dict(zip(['PC{}'.format(pci + 1) for pci in range(n_PCs)], range(n_PCs))),\n",
    "                'label_phe_stackedbar':  label_phe_stackedbar,\n",
    "                'label_gene_stackedbar': label_gene_stackedbar,\n",
    "                'stackedbar_phe':  stackedbar_phe_json,\n",
    "                'stackedbar_gene': stackedbar_gene_json\n",
    "                }, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_json_data(\n",
    "    out_dir, dataset, n_PCs, n_phes, n_vars, \n",
    "    label_phe, label_var, label_phe_code, gene2Ensembl_dict,\n",
    "    factor_phe, factor_var, \n",
    "    contribution_phe, contribution_var, \n",
    "    cos_phe, cos_var,\n",
    "    label_phe_stackedbar, label_gene_stackedbar,\n",
    "    stackedbar_phe, stackedbar_gene,\n",
    "    loading_phe, loading_var\n",
    "):\n",
    "\n",
    "    loading_sq_phe = np.array(loading_phe) ** 2\n",
    "    loading_sq_var = np.array(loading_var) ** 2\n",
    "\n",
    "    if not os.path.exists(os.path.join(out_dir, dataset)):\n",
    "        os.makedirs(os.path.join(out_dir, dataset))    \n",
    "    for pci in range(n_PCs):\n",
    "        with open(os.path.join(out_dir, dataset, '{}_factor_phe_{}.json'.format(dataset, pci)), 'w') as f:\n",
    "            json.dump(factor_phe[:, pci].tolist(), f)\n",
    "        with open(os.path.join(out_dir, dataset, '{}_factor_var_{}.json'.format(dataset, pci)), 'w') as f:\n",
    "            json.dump(factor_var[:, pci].tolist(), f)    \n",
    "\n",
    "        contribution_phe_x, contribution_phe_y, contribution_phe_l, _ = sparsify_contributoin_scores(contribution_phe, label_phe, pci, 0.0001)\n",
    "        contribution_var_x, contribution_var_y, contribution_var_l, _ = sparsify_contributoin_scores(contribution_var, label_var, pci, 0.001)\n",
    "\n",
    "        with open(os.path.join(out_dir, dataset, '{}_contribution_phe_x_{}.json'.format(dataset, pci)), 'w') as f:\n",
    "            json.dump(contribution_phe_x.tolist(), f)\n",
    "        with open(os.path.join(out_dir, dataset, '{}_contribution_phe_y_{}.json'.format(dataset, pci)), 'w') as f:\n",
    "            json.dump(contribution_phe_y.tolist(), f)\n",
    "        with open(os.path.join(out_dir, dataset, '{}_contribution_phe_l_{}.json'.format(dataset, pci)), 'w') as f:\n",
    "            json.dump(contribution_phe_l.tolist(), f)\n",
    "        with open(os.path.join(out_dir, dataset, '{}_contribution_var_x_{}.json'.format(dataset, pci)), 'w') as f:\n",
    "            json.dump(contribution_var_x.tolist(), f)\n",
    "        with open(os.path.join(out_dir, dataset, '{}_contribution_var_y_{}.json'.format(dataset, pci)), 'w') as f:\n",
    "            json.dump(contribution_var_y.tolist(), f)\n",
    "        with open(os.path.join(out_dir, dataset, '{}_contribution_var_l_{}.json'.format(dataset, pci)), 'w') as f:\n",
    "            json.dump(contribution_var_l.tolist(), f)\n",
    "\n",
    "        loading_phe_x, loading_phe_y, loading_phe_l, _ = sparsify_contributoin_scores(loading_sq_phe, label_phe, pci, 0.0001)\n",
    "        loading_var_x, loading_var_y, loading_var_l, _ = sparsify_contributoin_scores(loading_sq_var, label_var, pci, 0.001)\n",
    "\n",
    "        with open(os.path.join(out_dir, dataset, '{}_loading_phe_x_{}.json'.format(dataset, pci)), 'w') as f:\n",
    "            json.dump(loading_phe_x.tolist(), f)\n",
    "        with open(os.path.join(out_dir, dataset, '{}_loading_phe_y_{}.json'.format(dataset, pci)), 'w') as f:\n",
    "            json.dump(loading_phe_y.tolist(), f)\n",
    "        with open(os.path.join(out_dir, dataset, '{}_loading_phe_l_{}.json'.format(dataset, pci)), 'w') as f:\n",
    "            json.dump(loading_phe_l.tolist(), f)\n",
    "        with open(os.path.join(out_dir, dataset, '{}_loading_var_x_{}.json'.format(dataset, pci)), 'w') as f:\n",
    "            json.dump(loading_var_x.tolist(), f)\n",
    "        with open(os.path.join(out_dir, dataset, '{}_loading_var_y_{}.json'.format(dataset, pci)), 'w') as f:\n",
    "            json.dump(loading_var_y.tolist(), f)\n",
    "        with open(os.path.join(out_dir, dataset, '{}_loading_var_l_{}.json'.format(dataset, pci)), 'w') as f:\n",
    "            json.dump(loading_var_l.tolist(), f)\n",
    "\n",
    "        bar_phe,  bar_phe_label  = stacked_bar_per_pc(stackedbar_phe,  label_phe_stackedbar,  pci)\n",
    "        bar_gene, bar_gene_label = stacked_bar_per_pc(stackedbar_gene, label_gene_stackedbar, pci)\n",
    "        bar_phe_code = [dict(zip(label_phe, label_phe_code))[x] for x in bar_phe_label]\n",
    "        bar_gene_code = [gene2Ensembl_dict[x] for x in bar_gene_label]\n",
    "\n",
    "        with open(os.path.join(out_dir, dataset, '{}_bar_phe_{}.json'.format(dataset, pci)), 'w') as f:\n",
    "            json.dump(bar_phe, f)\n",
    "        with open(os.path.join(out_dir, dataset, '{}_bar_phe_label_{}.json'.format(dataset, pci)), 'w') as f:\n",
    "            json.dump(bar_phe_label, f)\n",
    "        with open(os.path.join(out_dir, dataset, '{}_bar_phe_code_{}.json'.format(dataset, pci)), 'w') as f:\n",
    "            json.dump(bar_phe_code, f)\n",
    "        with open(os.path.join(out_dir, dataset, '{}_bar_gene_{}.json'.format(dataset, pci)), 'w') as f:\n",
    "            json.dump(bar_gene, f)\n",
    "        with open(os.path.join(out_dir, dataset, '{}_bar_gene_label_{}.json'.format(dataset, pci)), 'w') as f:\n",
    "            json.dump(bar_gene_label, f)\n",
    "        with open(os.path.join(out_dir, dataset, '{}_bar_gene_code_{}.json'.format(dataset, pci)), 'w') as f:\n",
    "            json.dump(bar_gene_code, f)\n",
    "                    \n",
    "    for phe in range(n_phes):\n",
    "        with open(os.path.join(out_dir, dataset, '{}_cos_phe_{}.json'.format(dataset, phe)), 'w') as f:\n",
    "            json.dump(cos_phe[phe, :].tolist(), f)    \n",
    "        with open(os.path.join(out_dir, dataset, '{}_loading_phe_{}.json'.format(dataset, phe)), 'w') as f:\n",
    "            json.dump(loading_sq_phe[phe, :].tolist(), f)\n",
    "\n",
    "    for var in range(n_vars):\n",
    "        with open(os.path.join(out_dir, dataset, '{}_cos_var_{}.json'.format(dataset, var)), 'w') as f:\n",
    "            json.dump(cos_var[var, :].tolist(), f)       \n",
    "        with open(os.path.join(out_dir, dataset, '{}_loading_var_{}.json'.format(dataset, var)), 'w') as f:\n",
    "            json.dump(loading_sq_var[var, :].tolist(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_prep_for_gbe_main(\n",
    "    in_data_dir, out_dir, dataset, variant_tsv, \n",
    "    stackedbar_threshold = 0.1, json_out = False, python_out = False, loading=False\n",
    "):\n",
    "    logger_main = logging.getLogger('data_prep_for_gbe_main')    \n",
    "    # filenames\n",
    "    label_phe_f     = os.path.join(in_data_dir, dataset, 'ap_icd_idx.tsv')\n",
    "    label_var_f     = os.path.join(in_data_dir, dataset, 'ap_variant_idx.tsv')\n",
    "    tsvd_f          = os.path.join(in_data_dir, dataset, 'ap_icd_var_tsvd.tsv')  \n",
    "    loading_phe_f   = os.path.join(in_data_dir, dataset, 'ap_icd_svd_cor1.tsv')  \n",
    "    loading_var_f   = os.path.join(in_data_dir, dataset, 'ap_icd_svd_cor2.tsv')  \n",
    "    meta_f          = os.path.join(in_data_dir, dataset, 'metadata.txt')\n",
    "    total_inertia_f = os.path.join(in_data_dir, dataset, 'total_inertia.txt')\n",
    "\n",
    "    # meta data\n",
    "    with open(meta_f) as f:\n",
    "        metadata = f.read().splitlines()\n",
    "    metadata.append('data conversion script has started on {}'.format(str(datetime.now())))\n",
    "    \n",
    "    # total inertia\n",
    "    with open(total_inertia_f) as f:\n",
    "        total_inertia = float(f.read().splitlines()[0])\n",
    "\n",
    "    # read dict to convert label_var to label_gene \n",
    "    variant_df = pd.read_csv(variant_tsv, sep='\\t')\n",
    "    var2gene_dict = dict(zip(variant_df['label_var'], variant_df['label_gene']))    \n",
    "    gene2Ensembl_dict = dict(zip(variant_df['label_gene'], variant_df['Gene']))    \n",
    "    \n",
    "    logger_main.info('reading labels and eigen values ...')\n",
    "    # read the data (1) labels and eigen values\n",
    "    label_phe, label_phe_code = parse_label_phe(label_phe_f)\n",
    "    label_var_unsorted = parse_label_var(label_var_f)\n",
    "    eigen_v = read_eigen_values(tsvd_f)\n",
    "\n",
    "    # sort variant labels\n",
    "    label_var_argsort = np.argsort(\n",
    "        [int(x.split('-')[1]) + 1000000000 * int(x.split('-')[0]) for x in label_var_unsorted]\n",
    "    )    \n",
    "    label_var = label_var_unsorted[label_var_argsort]\n",
    "\n",
    "    # get the number of PCs, variants, and phenotyps\n",
    "    n_phes = len(label_phe)\n",
    "    n_vars = len(label_var)\n",
    "    n_PCs = len(eigen_v)\n",
    "\n",
    "    logger_main.info('reading eigen vectors ...')    \n",
    "    # read the data (2) eigen vectors\n",
    "    eigen_phe, eigen_var_unsorted = read_eigen_vectors(tsvd_f, n_PCs, n_phes, n_vars)\n",
    "    eigen_var = eigen_var_unsorted[label_var_argsort, :]\n",
    "\n",
    "    # read the data (3) loading (correlation of phenotype/variant vector and PCs)\n",
    "    if(loading):\n",
    "        logger_main.info('reading phenotype loading (correlation) ...')    \n",
    "        loading_phe = dok_from_tsv(loading_phe_f).todense()\n",
    "        logger_main.info('reading variant loading (correlation) ...')    \n",
    "        loading_var = dok_from_tsv(loading_var_f).todense()\n",
    "    else:\n",
    "        loading_phe = np.ones((n_phes, n_PCs))\n",
    "        loading_var = np.ones((n_vars, n_PCs))\n",
    "\n",
    "    logger_main.info('computing scores ...')        \n",
    "    # convert to factor scores\n",
    "    factor_phe = compute_factor(eigen_phe, eigen_v)\n",
    "    factor_var = compute_factor(eigen_var, eigen_v)\n",
    "\n",
    "    # compute cosine scores & contribution scores\n",
    "    contribution_phe = compute_contribution(factor_phe)\n",
    "    contribution_var = compute_contribution(factor_var)\n",
    "    cos_phe = compute_cos(factor_phe)\n",
    "    cos_var = compute_cos(factor_var)\n",
    "    \n",
    "    contribution_gene, label_gene = compute_contribution_gene(\n",
    "        var2gene_dict, label_var, contribution_var\n",
    "    )    \n",
    "    \n",
    "    # compute data for stacked bar plots\n",
    "    stackedbar_phe, label_phe_stackedbar = generate_data_mat_for_stacked_bar(\n",
    "        contribution_phe, label_phe, stackedbar_threshold\n",
    "    )\n",
    "    stackedbar_gene, label_gene_stackedbar = generate_data_mat_for_stacked_bar(\n",
    "        contribution_gene, label_gene, stackedbar_threshold\n",
    "    )\n",
    "    \n",
    "    if(python_out):\n",
    "        out_file = os.path.join(out_dir, '{}.npz'.format(dataset))\n",
    "        # write to a python npz file\n",
    "        logger_main.info('writing to npz file: {} ...'.format(out_file))\n",
    "        np.savez_compressed(\n",
    "            out_file, \n",
    "            total_inertia     = np.array([total_inertia]),\n",
    "            eigen_v           = np.array(eigen_v),             \n",
    "            eigen_phe         = np.array(eigen_phe),\n",
    "            eigen_var         = np.array(eigen_var),\n",
    "            label_phe         = np.array(label_phe), \n",
    "            label_var         = np.array(label_var),\n",
    "            label_phe_code    = np.array(label_phe_code),\n",
    "            label_gene        = np.array(label_gene),        \n",
    "            label_phe_stackedbar  = np.array(label_phe_stackedbar),\n",
    "            label_gene_stackedbar = np.array(label_gene_stackedbar),        \n",
    "            factor_phe        = np.array(factor_phe), \n",
    "            factor_var        = np.array(factor_var),\n",
    "            contribution_phe  = np.array(contribution_phe),\n",
    "            contribution_var  = np.array(contribution_var),\n",
    "            contribution_gene = np.array(contribution_gene),\n",
    "            cos_phe           = np.array(cos_phe),\n",
    "            cos_var           = np.array(cos_var),\n",
    "            stackedbar_phe    = np.array(stackedbar_phe),\n",
    "            stackedbar_gene   = np.array(stackedbar_gene),\n",
    "            loading_phe       = np.array(loading_phe),\n",
    "            loading_var       = np.array(loading_var),\n",
    "            metadata          = np.array(metadata)\n",
    "        )  \n",
    "        \n",
    "    if(json_out):\n",
    "        # write to a JSON file\n",
    "        logger_main.info('writing to JSON files ...')            \n",
    "        write_json_misc(\n",
    "            out_dir, dataset, metadata, n_PCs, total_inertia, eigen_v, \n",
    "            label_phe.tolist(), \n",
    "            label_var.tolist(), \n",
    "            label_phe_code.tolist(), \n",
    "            label_gene.tolist(),\n",
    "            label_phe_stackedbar.tolist(),\n",
    "            label_gene_stackedbar.tolist(),\n",
    "            stackedbar_phe, \n",
    "            stackedbar_gene\n",
    "        )\n",
    "\n",
    "        # write to small json files\n",
    "        write_json_data(\n",
    "            out_dir, dataset, n_PCs, n_phes, n_vars, \n",
    "            label_phe, label_var, label_phe_code, gene2Ensembl_dict, \n",
    "            factor_phe, factor_var, contribution_phe, contribution_var, \n",
    "            cos_phe, cos_var, \n",
    "            label_phe_stackedbar, label_gene_stackedbar,\n",
    "            stackedbar_phe, stackedbar_gene,\n",
    "            loading_phe, loading_var\n",
    "        )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-12-01 22:34:49,283 data_prep_for_gbe_main INFO     reading labels and eigen values ...\n",
      "2017-12-01 22:34:49,461 data_prep_for_gbe_main INFO     reading eigen vectors ...\n",
      "2017-12-01 22:34:54,549 data_prep_for_gbe_main INFO     computing scores ...\n",
      "2017-12-01 22:34:54,693 data_prep_for_gbe_main INFO     writing to npz file: /opt/biobankengine/GlobalBioBankEngineRepo/gbe_browser/static/decomposition/dev_PTVs_z_nonCenter_p001_100PCs.npz ...\n",
      "2017-12-01 22:34:55,425 data_prep_for_gbe_main INFO     writing to JSON files ...\n"
     ]
    }
   ],
   "source": [
    "data_prep_for_gbe_main(\n",
    "    in_data_dir = '/home/scidb/R_code/results/',\n",
    "    out_dir     = '/opt/biobankengine/GlobalBioBankEngineRepo/gbe_browser/static/decomposition',\n",
    "    dataset     = 'dev_PTVs_z_nonCenter_p001_100PCs',\n",
    "    variant_tsv = '/home/ytanigaw/repos/rivas-lab/decomposition/private_data/variant_and_gene_labels.tsv',\n",
    "    stackedbar_threshold = 0.1,\n",
    "    json_out   = True,\n",
    "    python_out = True,\n",
    "    loading     = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
